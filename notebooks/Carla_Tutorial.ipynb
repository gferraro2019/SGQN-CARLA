{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6f78216",
   "metadata": {},
   "source": [
    "# What is CARLA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c098d8",
   "metadata": {},
   "source": [
    "CARLA is an open-source autonomous driving simulator. It was built from scratch to serve as a modular and flexible API to address a range of tasks involved in the problem of autonomous driving.\n",
    "\n",
    "CARLA simulates a highly realistic environment emulating real world towns, cities and highways and the vehicles and other objects that occupy these driving spaces.\n",
    "\n",
    "### About Training:\n",
    "The CARLA simulator is a comprehensive solution for producing synthetic training data for applications in autonomous driving (AD) and also other robotics applications. \n",
    "\n",
    "### About Testing:\n",
    "You can deploy the AD agents you have trained within the simulation to test and evaluate their performance and safety, all within the security of a simulated environment, with no risk to hardware or other road users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea4ae8",
   "metadata": {},
   "source": [
    "# What is its goal?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9be7f8",
   "metadata": {},
   "source": [
    "One of the main goals of CARLA is to help democratize autonomous driving R&D, serving as a tool that can be easily accessed and customized by users (e.g. learning driving policies, training perception algorithms, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e3947e",
   "metadata": {},
   "source": [
    "# What's under the hood of Carla?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f8129",
   "metadata": {},
   "source": [
    "CARLA is grounded on Unreal Engine to run the simulation and uses the OpenDRIVE standard (1.4 as today) to define roads and urban settings. Control over the simulation is granted through an API handled in Python and C++ that is constantly growing as the project does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdf5be",
   "metadata": {},
   "source": [
    "# How  does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a2616",
   "metadata": {},
   "source": [
    "The CARLA simulator consists of a scalable client-server architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b104e",
   "metadata": {},
   "source": [
    "<img src=\"./pictures/carla_modules.webp\" alt = \"Structure of Carla\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce713994",
   "metadata": {},
   "source": [
    "## The server:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a83c9e",
   "metadata": {},
   "source": [
    "The server is responsible for everything related with the simulation itself: sensor rendering, computation of physics, updates on the world-state and its actors and much more. As it aims for realistic results, the best fit would be running the server with a dedicated GPU, especially when dealing with machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d563f4",
   "metadata": {},
   "source": [
    "## The Client:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1e564",
   "metadata": {},
   "source": [
    "The client side consists of a sum of client modules controlling the logic of actors on scene and setting world conditions. This is achieved by leveraging the CARLA API (in Python or C++), a layer that mediates between server and client that is constantly evolving to provide new functionalities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cc622",
   "metadata": {},
   "source": [
    "## Some of the capabilietes of what Carla can achieve:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a66f8d",
   "metadata": {},
   "source": [
    "<b><li>Traffic manager.</b>A built-in system that takes control of the vehicles besides the one used for learning. It acts as a conductor provided by CARLA to recreate urban-like environments with realistic behaviours.\n",
    "<br><br>\n",
    "<b><li>Sensors.</b> Vehicles rely on them to dispense information of their surroundings. In CARLA they are a specific kind of actor attached the vehicle and the data they receive can be retrieved and stored to ease the process. Currently the project supports different types of these, <mark  style=\"background: yellow;\n",
    "  color:black\">from cameras to radars, lidar and many more.</mark>\n",
    "<br><br>\n",
    "<b><li>Recorder.</b>This feature is used to reenact a simulation step by step for every actor in the world. It grants access to any moment in the timeline anywhere in the world, making for a great tracing tool.\n",
    "<br><br>\n",
    "<b><li>ROS bridge and Autoware implementation.</b>As a matter of universalization, the CARLA project ties knots and works for the integration of the simulator within other learning environments.\n",
    "<br><br>\n",
    "<b><li>Open assets.</b>CARLA facilitates different maps for urban settings with <mark  style=\"background: yellow;\n",
    "  color:black\">control over weather conditions and a blueprint library with a wide set of actors to be used.</mark> However, these elements can be customized and new can be generated following simple guidelines.\n",
    "<br><br>\n",
    "<b><li>Scenario runner.</b>In order to ease the learning process for vehicles, CARLA provides a series of routes describing different situations to iterate on. These also set the basis for the CARLA challenge, open for everybody to test their solutions and make it to the leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32daf292",
   "metadata": {},
   "source": [
    "# How to install it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b410b08",
   "metadata": {},
   "source": [
    "https://carla.readthedocs.io/en/latest/start_quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01ddbb",
   "metadata": {},
   "source": [
    "# How to run CARLA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657b9f9d",
   "metadata": {},
   "source": [
    "## 1. Start the server:\n",
    "<ol>\n",
    "    <li>Run the executable file either the CarlaUE4.sh or CarlaUE4.exe according to your OS. </li>\n",
    "    <li>A window containing a view over the city will pop up. This is the spectator view.<br></li>\n",
    "    <li>To fly around the city use the mouse and WASD keys, holding down the right mouse button to control the direction.</li>\n",
    "</ol> \n",
    "\n",
    "#### The server simulator is now running and waiting for a client to connect and interact with the world\n",
    "\n",
    "#### To use the server in no rendering mode: \n",
    "./CarlaUE4.sh -RenderOffScreen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebeb97",
   "metadata": {},
   "source": [
    "## 2. Start the client:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48885c",
   "metadata": {},
   "source": [
    "You can combine several scripts in order to generate the scenario that you desire, for instance from the .../PythonPI/examples:<br>\n",
    "<ul>\n",
    "    <li> to spawn life into the city  run: generate_traffic.py\n",
    "    <li> to have dynamic weather run: dynamic_weather.py\n",
    "    <li> to drive a car manually run: manual_control.py\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e2904",
   "metadata": {},
   "source": [
    "### The main advantage of client-server acrhitecture:\n",
    "\n",
    "This way, the CARLA server can be run on a networked machine, while the python client can be run from a personal computer. This is particularly useful for <mark  style=\"background: yellow;\n",
    "  color:black\">differentiating the GPU used for running the CARLA simulator and that used for neural network training,</mark> both of which can be highly demanding on graphics hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55306b80",
   "metadata": {},
   "source": [
    "# How to record on Carla?\n",
    "There are 2 different ways of recordings in carla.\n",
    "\n",
    "## Via snapshots:\n",
    "It is possible to aquire the images from a sensor attached to the actor of interest. For instance a picture will be acuired every tick from the camera attached on a car.\n",
    "\n",
    "## Via .log file:\n",
    "A log file is created thatincludes information regarding many different elements.\n",
    "<ul>\n",
    "<li>Actors — creation and destruction, bounding and trigger boxes.</li>\n",
    "<li>Traffic lights — state changes and time settings.</li>\n",
    "<li>Vehicles — position and orientation, linear and angular velocity, light state, and physics control.</li>\n",
    "<li>Pedestrians — position and orientation, and linear and angular velocity.</li>\n",
    "<li>Lights — Light states from buildings, streets, and vehicles.  These is the way for testing different agents with the exact conditions of the others.</li>\n",
    "</ul>\n",
    "\n",
    "Generally, a sencond script is launched where only a client is defined to start the recoding session.The script does it at the very beginning, in order to capture everything, including the spawning of the first actors. If no path is detailed, the log will be saved into CarlaUE4/Saved.\n",
    "\n",
    "To start recording there is only need for a file name. Using \\, / or : characters in the file name will define it as an absolute path. If no path is detailed, the file will be saved in CarlaUE4/Saved.\n",
    "\n",
    "    client.start_recorder(\"/home/carla/recording01.log\")\n",
    "\n",
    "By default, the recorder is set to store only the necessary information to play the simulation back. In order to save all the information previously mentioned, the argument additional_data has to be configured when starting the recording.\n",
    "    \n",
    "    client.start_recorder(\"/home/carla/recording01.log\",True)\n",
    "    \n",
    "To stop the recording, the call is also straightforward.\n",
    "    \n",
    "    client.stop_recorder()\n",
    "\n",
    "\n",
    "### Example of a script for recoding 5 minutes of simulation:\n",
    "    #Assuming that the server is already running\n",
    "\n",
    "    impor time\n",
    "    t = time.time()\n",
    "    duration = 300 #seconds\n",
    "    # Start recording\n",
    "    client.start_recorder('~/tutorial/recorder/recording01.log')\n",
    "    while time.time() - t < duration:\n",
    "        pass\n",
    "    # Stop recording\n",
    "    client.stop_recorder()\n",
    "\n",
    "Once the simulation has been recorded, it is time to examine the recording, find the most remarkable moments, and work with them. These steps are gathered in the script, tutorial_replay.py.\n",
    "\n",
    "### Simulation playback:\n",
    "A playback can be started at any point during a simulation. Besides the path to the log file, this method needs some parameters.\n",
    "    \n",
    "    client.replay_file(\"recording01.log\", start, duration, camera)\n",
    "    \n",
    "#### Setting a time factor:\n",
    "The time factor will determine the playback speed. It can be changed any moment without stopping the playback.\n",
    "    \n",
    "    client.set_replayer_time_factor(2.0)\n",
    "    \n",
    "### Queries:\n",
    "It is possible to retreive only the information of a specific actor through the use of queries.\n",
    "    \n",
    "    # --------------\n",
    "    # Query the recording\n",
    "    # --------------\n",
    "    # Show only the most important events in the recording.  \n",
    "    print(client.show_recorder_file_info(\"~/tutorial/recorder/recording01.log\",False))\n",
    "    \n",
    "    # Show actors not moving 1 meter in 10 seconds.  \n",
    "    print(client.show_recorder_actors_blocked(\"~/tutorial/recorder/recording01.log\",10,1))\n",
    "    \n",
    "    # Filter collisions between vehicles 'v' and 'a' any other type of actor.  \n",
    "    print(client.show_recorder_collisions(\"~/tutorial/recorder/recording01.log\",'v','a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a406f",
   "metadata": {},
   "source": [
    "# The Python API:\n",
    "For those of you who want to dive directly and deeply on the API, please click <a href=\"https://carla.readthedocs.io/en/latest/python_api/\">here<a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa0f379",
   "metadata": {},
   "source": [
    "# Firtst Project:\n",
    "\n",
    "We assume the simulator is already running on the server-side, either in rendered mode or in the no-rendering mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc9de89",
   "metadata": {},
   "source": [
    "### The logical structure:\n",
    "    1. Create the client object\n",
    "    2. Get the world object\n",
    "    3. Loading the map\n",
    "    4. Select the actors and their blueprints\n",
    "    5. Get the spawn points\n",
    "    6. Get the Ego vehicle\n",
    "    7. Set the sensors, recording\n",
    "    8. Animate actors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c24b64",
   "metadata": {},
   "source": [
    "## 1. and 2. Create the client and get the world object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84800868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import random\n",
    "\n",
    "# Connect to the client \n",
    "client = carla.Client('localhost', 2000)\n",
    "# Retrieve the world object\n",
    "world = client.get_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ac5a57",
   "metadata": {},
   "source": [
    "### The Client Object:\n",
    "\n",
    "The client is the module the user runs to ask for information or changes in the simulation.<br>\n",
    "A client runs with an IP and a specific port.<br>\n",
    "It communicates with the server via terminal. There can be many clients running at the same time. Advanced multiclient managing requires thorough understanding of CARLA and <a href=\"https://carla.readthedocs.io/en/latest/adv_synchrony_timestep/\">synchrony</a>.\n",
    "\n",
    "It serves <b>to maintain the client's connection to the server</b> and has a number of functions for applying commands and loading or exporting data. We can load an alternative map or reload the current one (resetting to initial state) using\n",
    "the client object.\n",
    "\n",
    "The <i>Port</i> can be chosen as any available port and is set to 2000 by default on the server, you can also choose a host different from localhost by using a computer's IP address.\n",
    "\n",
    "### The Wolrd Object:\n",
    "The world is an object representing the simulation.<br>\n",
    "It acts as an abstract layer containing the main methods to spawn actors, change the weather, get the current state of the world, etc.<br>\n",
    "There is only one world per simulation and it will be destroyed and substituted for a new one when the map is changed.\n",
    "\n",
    "It provides access to all elements of the simulation, including the map, objects within the map, such as buildings, traffic lights, vehicles and pedestrians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2384e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the map\n",
    "level = world.get_map()\n",
    "# Get the weather\n",
    "weather = world.get_weather()\n",
    "# Get the blueorint library object that contains all the blueprint of the available veichles(cars, bikes, etc.)\n",
    "blueprint_library = world.get_blueprint_library()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ef740",
   "metadata": {},
   "source": [
    "### Synchronous and asynchronous mode\n",
    "CARLA has a client-server architecture. The server runs the simulation. The client retrieves information and requests changes in the simulation.\n",
    "\n",
    "By default, CARLA runs in asynchronous mode.\n",
    "\n",
    "Essentially, in asynchronous mode the CARLA server runs as fast as it can. Client requests are handled on the fly. In synchronous mode the client, running your Python code, takes the reigns and tells the server when to update.\n",
    "\n",
    "#### When is it convienent to use A-sync mode?\n",
    "Asynchronous mode is an appropriate mode to run CARLA if you are experimenting or setting up a simulation, so you can fly around the map with the spectator as you place your actors. \n",
    "\n",
    "#### When is it convienent to use Sync mode?\n",
    "When you want to start producing training data or deploying an agent within the simulation, it is advised that you use the synchronous mode since this will give you more control and predictability.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a183c85",
   "metadata": {},
   "source": [
    "## 3. Loading the map:\n",
    "The CARLA server normally loads a default map (normally Town10). If you want to launch CARLA with an alternate map, you have two ways:\n",
    "\n",
    "\n",
    "#### From Server-side:\n",
    "You can use the config.py script:<br>\n",
    "./config.py --map Town05 \n",
    "\n",
    "#### From Client-side:\n",
    "You can use the world object to load a map from the client:<br>\n",
    "client.load_world('Town05')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0f811",
   "metadata": {},
   "source": [
    "Please find more information about CARLA maps <a href=\"https://carla.readthedocs.io/en/latest/core_map/\">here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a96db5",
   "metadata": {},
   "source": [
    "## Spectator navigation\n",
    "The spectator is a view into the simulation. By default, the spectator opens in a new window when you run the CARLA server on a computer with a screen attached, unless you specify the -RenderOffScreen command line option.\n",
    "\n",
    "The spectator is helpful to visualize your simulation. Using the spectator, you can familiarize yourself with the map you've loaded, and see the result of any changes you are making, such as adding vehicles, changing the weather, turning on/off various layers of the map and for debugging purposes.\n",
    "\n",
    "You can fly the spectator around the world using the mouse to control the pitch and yaw of the spectator view and the QWE-ASD keys to move the spectator:\n",
    "\n",
    "Q - move upwards (towards the top edge of the window)<br>\n",
    "E - move downwards (towards the lower edge of the window)<br>\n",
    "W - move forwards<br>\n",
    "S - move backwards<br>\n",
    "A - move left<br>\n",
    "D - move right<br>\n",
    "\n",
    "Left click and drag the mouse in the spectator window up and down to control pitch and left and right to control yaw.\n",
    "\n",
    "<img src =\"https://carla.readthedocs.io/en/latest/img/tuto_G_getting_started/flying_spectator.gif\" alt=\"Carla Spectator Gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f0565",
   "metadata": {},
   "source": [
    "#### The spectator and its properties can be accessed and manipulated through the Python API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c43923c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the spectator object\n",
    "spectator = world.get_spectator()\n",
    "\n",
    "# Get the location and rotation of the spectator through its transform\n",
    "transform = spectator.get_transform()\n",
    "\n",
    "location = transform.location\n",
    "rotation = transform.rotation\n",
    "\n",
    "# Set the spectator with an empty transform\n",
    "spectator.set_transform(carla.Transform())\n",
    "# This will set the spectator at the origin of the map, with 0 degrees\n",
    "# pitch, yaw and roll - a good way to orient yourself in the map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3856338",
   "metadata": {},
   "source": [
    "#### Nomenclature of the 6 degrees of fredom:\n",
    "<img src=\"pictures/6_degrees_of_freedom.jpg\" width=\"400\" height=\"400\" style=\"padding:10px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd785e2",
   "metadata": {},
   "source": [
    "## Actors and Blueprints\n",
    "Actors in CARLA are the elements that perform actions within the simulation, and they can affect other actors. Actors in CARLA includes vehicles and walkers and also sensors, traffic signs, traffic lights and the spectator.\n",
    "\n",
    "The Blueprints are layouts that allow the user to smoothly incorporate new actors into the simulation. They are already-made models with animations and a series of attributes. Some of these are modifiable and others are not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330b02f0",
   "metadata": {},
   "source": [
    "### Examples of how to manage the blueprint library\n",
    "The carla.BlueprintLibrary class contains a list of carla.ActorBlueprint elements. It is the world object who can provide access to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e31636ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint_library = world.get_blueprint_library()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbc4479",
   "metadata": {},
   "source": [
    "Blueprints have an ID to identify them and the actors spawned with it. The library can be read to find a certain ID, choose a blueprint at random, or filter results using a wildcard pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe3d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a specific blueprint.\n",
    "collision_sensor_bp = blueprint_library.find('sensor.other.collision')\n",
    "# Choose a vehicle blueprint at random.\n",
    "vehicle_bp = random.choice(blueprint_library.filter('vehicle.*.*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ac9b0f",
   "metadata": {},
   "source": [
    "Besides that, each carla.ActorBlueprint has a series of carla.ActorAttribute that can be get and set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1d8830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of wheels of the random veichle\n",
    "vehicle_bp.get_attribute('number_of_wheels').as_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "324de21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "veichles = blueprint_library.filter('vehicle.*.*')\n",
    "bikes = [v for v in veichles if v.get_attribute('number_of_wheels').as_int() == 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32fb6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same color for all the bikes\n",
    "for b in bikes:\n",
    "    b.set_attribute('color', '255,0,0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78afd6cd",
   "metadata": {},
   "source": [
    "## Adding Non-player Characters (NCPs):\n",
    "We now can populate our simulation with some vehicles to simulate a real environment with traffic and other road users or non-player characters (NPCs).\n",
    "\n",
    "The carla.BlueprintLibrary class contains a list of carla.ActorBlueprint elements. It is the world object who can provide access to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede0b880",
   "metadata": {},
   "source": [
    "### 4. Select the Actors and their Blueprints:\n",
    "To spawn vehicles, first, we need to select the vehicles we want from the blueprint library. As below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0715e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the blueprint library and filter for the vehicle blueprints\n",
    "vehicle_blueprints = world.get_blueprint_library().filter('*vehicle*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ad57b",
   "metadata": {},
   "source": [
    "### 5. Get the Spawn points:\n",
    "Now we have the blueprints, we need to find some appropriate spots in the map to spawn our vehicles. Each CARLA map provides pre-defined spawn points spread evenly throughout the map on the roads for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3c2981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the map's spawn points\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "# Spawn 50 vehicles randomly distributed throughout the map \n",
    "# for each spawn point, we choose a random vehicle from the blueprint library\n",
    "for i in range(0,50):\n",
    "    world.try_spawn_actor(random.choice(vehicle_blueprints), random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f85ddee",
   "metadata": {},
   "source": [
    "### 6. Get the main vehicle or \"Ego vehicle\":\n",
    "We need to set a vehicle as the one that will be the centerpoint of our simulation. That is, the vehicle that the autonomous agent will control. In CARLA parlance, we often refer to this vehicle as the \"Ego vehicle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79e7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment for random ego vehicle\n",
    "ego_vehicle = None\n",
    "while ego_vehicle is None:\n",
    "    ego_vehicle = world.try_spawn_actor(random.choice(vehicle_blueprints), random.choice(spawn_points))\n",
    "\n",
    "# uncomment for a specific vehilcle \n",
    "#ego_vehicle = world.spawn_actor(bikes[0], random.choice(spawn_points))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253d26d",
   "metadata": {},
   "source": [
    "Notice that it is possibile to spawn an Ego veichle also with <b>world.spawn_actor()</b> method but it will raise an error in case of collision, while <b>world.try_spawn_actor()</b> will return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b8dcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aquire the point of view of Ego veichle, that is, set the spectator on Ego position\n",
    "transform = ego_vehicle.get_transform()\n",
    "location = carla.Location(x=transform.location.x, y=transform.location.y, z=70)\n",
    "spectator.set_transform(carla.Transform(location, carla.Rotation(roll=0,yaw=180.0, pitch=-90.0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2731074e",
   "metadata": {},
   "source": [
    "CARLA uses the Unreal Engine coordinates system. Remember that carla.Rotation constructor is defined as (pitch, yaw, roll), that differs from Unreal Engine Editor (roll, pitch, yaw)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100697cd",
   "metadata": {},
   "source": [
    "In addition to vehicles, CARLA also provides pedestrians to add to simulations to simulate realistic driving scenarios. Vehicles and pedestrians are referred to as actors in the CARLA parlance, learn more about them <a href=\"https://carla.readthedocs.io/en/latest/core_actors/\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b010d",
   "metadata": {},
   "source": [
    "## 7. Add sensors:\n",
    "CARLA has models of numerous types of sensors built in to create training data for machine learning. The sensors can be attached to a vehicle, or they can be attached to a fixed point to model for example a CCTV camera.\n",
    "\n",
    "### The process to spawn any sensor:\n",
    "\n",
    "1. Use the library to find sensor blueprints.\n",
    "2. Set specific attributes for the sensor. This is crucial. Attributes will shape the data retrieved.\n",
    "3. Attach the sensor to the ego vehicle. The transform is relative to its parent. The carla.AttachmentType will determine how the position of the sensor is updated.\n",
    "4. Add a listen() method. This is the key element. A lambda method that will be called each time the sensor listens for data. The argument is the sensor data retrieved.\n",
    "\n",
    "Here we will attach a standard camera sensor to the ego vehicle to record some video data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9927e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform to place the camera on top of the vehicle\n",
    "camera_init_trans = carla.Transform(carla.Location(z=1.5))\n",
    "\n",
    "# We create the camera through a blueprint that defines its properties\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "\n",
    "# We spawn the camera and attach it to our ego vehicle\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=ego_vehicle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351cc190",
   "metadata": {},
   "source": [
    "Once we have spawned the camera, we need to set it recording through the <b>listen()</b> method. The listen method takes as argument a callback that defines what to do with the data. You can either stream it to another program or save it to disk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a752739",
   "metadata": {},
   "source": [
    "### Recording on the disk:\n",
    "We will use a lambda function as a callback to save the data to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22283315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start camera with PyGame callback\n",
    "camera.listen(lambda image: image.save_to_disk('out/%06d.png' % image.frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a202a8b",
   "metadata": {},
   "source": [
    "This will save the data to the out/ folder <b>as a series of PNG image files</b> named according to the simulation frame number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bbf45d",
   "metadata": {},
   "source": [
    "There are a multitude of different types of sensors to choose from. <a href=\"https://carla.readthedocs.io/en/latest/core_sensors/\">Here</a> you can delve deeper into the array of sensors available and how to use them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb90f19",
   "metadata": {},
   "source": [
    "## 8. Animate Actors:\n",
    "Now we've added our traffic and ego vehicle to the simulation and started recording camera data, we now need to set the vehicles in motion using the <a href=\"https://carla.readthedocs.io/en/latest/tuto_G_traffic_manager/\"><b>Traffic manager</b></a>.<br>\n",
    "\n",
    "### The Traffic manager: \n",
    "It is a component of CARLA that controls vehicles to autonomously move around the roads of the map within the simulation, following the road conventions and behaving like real road users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51930a4",
   "metadata": {},
   "source": [
    "We can find all the vehicles in the simulation using the world.get_actors() method, filtering for all the vehicles. We can then use the set_autopilot() method to hand over control of the vehicle to the Traffic Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea96ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in world.get_actors().filter('*vehicle*'):\n",
    "    vehicle.set_autopilot(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413d46f",
   "metadata": {},
   "source": [
    "Now your simulation is running, with numerous vehicles driving around the map and a camera recording data from one of those vehicles. This data can then be used to feed a machine learning algorithm for training an autonomous driving agent. The Traffic manager has many functions for customising traffic behaviour, learn more here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484c141f",
   "metadata": {},
   "source": [
    "Now your simulation is running, with numerous vehicles driving around the map and a camera recording data from one of those vehicles. This data can then be used to feed a machine learning algorithm for training an autonomous driving agent. The Traffic manager has many functions for customising traffic behaviour, learn more here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb1d9ac",
   "metadata": {},
   "source": [
    "#### Stop recording on the camera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1c19f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera has been stopped\n"
     ]
    }
   ],
   "source": [
    "# Record 60 seconds of pictures\n",
    "import time \n",
    "t = time.time()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    if time.time() - t < 60:\n",
    "        pass\n",
    "    else:    \n",
    "        camera.stop()\n",
    "        done = True\n",
    "print(\"Camera has been stopped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48c6ebc",
   "metadata": {},
   "source": [
    "#### Remove the veichles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f70234db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensor.camera.rgb\n",
      "sensor.camera.rgb\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "sensor.camera.rgb\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "traffic.traffic_light\n",
      "sensor.camera.rgb\n",
      "traffic.traffic_light\n",
      "traffic.unknown\n",
      "traffic.unknown\n",
      "traffic.unknown\n",
      "traffic.yield\n",
      "traffic.stop\n",
      "traffic.stop\n",
      "traffic.stop\n",
      "spectator\n"
     ]
    }
   ],
   "source": [
    "actors = world.get_actors()\n",
    "\n",
    "# Remove all the veichles\n",
    "for a in actors:\n",
    "    if  \"vehicle\" in a.type_id:\n",
    "        a.destroy()\n",
    "    else:\n",
    "        # Print the remaining actors\n",
    "        print(a.type_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
